{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39KRRwtWRsIc",
        "outputId": "201275f9-bfc8-4d4d-8c55-e053e25240f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.8.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.25.2)\n",
            "Collecting nir (from snntorch)\n",
            "  Downloading nir-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nirtorch (from snntorch)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m918.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nir, nvidia-cusolver-cu12, nirtorch, snntorch\n",
            "Successfully installed nir-1.0.1 nirtorch-1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 snntorch-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "metadata": {
        "id": "IeD7mm02R4ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader arguments\n",
        "batch_size = 128\n",
        "data_path='/tmp/data/mnist'\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "i8yVTc7BR_zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "275M86axSEgl",
        "outputId": "081a3d0f-011f-4ac8-fb78-44db521a3998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 86610291.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 9132666.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 29429826.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11774121.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "-A_gBdsRS8zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Architecture\n",
        "num_inputs = 28*28\n",
        "num_hidden = 1000\n",
        "num_outputs = 10\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 25\n",
        "beta = 0.95"
      ],
      "metadata": {
        "id": "_jSQZcWjTAWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "va5rWR5KTEHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass data into the network, sum the spikes over time\n",
        "# and compare the neuron with the highest number of spikes\n",
        "# with the target\n",
        "\n",
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    output, _ = net(data.view(batch_size, -1))\n",
        "    _, idx = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "    if train:\n",
        "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "\n",
        "def train_printer(\n",
        "    data, targets, epoch,\n",
        "    counter, iter_counter,\n",
        "        loss_hist, test_loss_hist, test_data, test_targets):\n",
        "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
        "    print_batch_accuracy(data, targets, train=True)\n",
        "    print_batch_accuracy(test_data, test_targets, train=False)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "KqycP3SbTXHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "aDps5yVrTdnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "kLgUtwtCTgjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, targets = next(iter(train_loader))\n",
        "data = data.to(device)\n",
        "targets = targets.to(device)"
      ],
      "metadata": {
        "id": "Opi9Aua5TjQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
        "print(mem_rec.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4bUgg2WTmZ4",
        "outputId": "81ec29c0-6659-4bb2-fb5e-a7b496bc2d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the total loss value\n",
        "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "# sum loss at every step\n",
        "for step in range(num_steps):\n",
        "  loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "print(f\"Training loss: {loss_val.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFuD7uFATp1c",
        "outputId": "1448cdca-2829-4c72-956a-6eb4accd39e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 59.638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_batch_accuracy(data, targets, train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC6CHGfmTsoF",
        "outputId": "13e98d79-b2b3-4d04-934c-ce3ace53238d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy for a single minibatch: 8.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear previously stored gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# calculate the gradients\n",
        "loss_val.backward()\n",
        "\n",
        "# weight update\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "ftmEQQeqVFht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate new network outputs using the same data\n",
        "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
        "\n",
        "# initialize the total loss value\n",
        "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "# sum loss at every step\n",
        "for step in range(num_steps):\n",
        "  loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "print(f\"Training loss: {loss_val.item():.3f}\")\n",
        "print_batch_accuracy(data, targets, train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeT6DCXQVH8W",
        "outputId": "1e2036c4-1cbd-4738-df6d-9ba5273e8d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 50.385\n",
            "Train set accuracy for a single minibatch: 58.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    iter_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data, targets in train_batch:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "        for step in range(num_steps):\n",
        "            loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        with torch.no_grad():\n",
        "            net.eval()\n",
        "            test_data, test_targets = next(iter(test_loader))\n",
        "            test_data = test_data.to(device)\n",
        "            test_targets = test_targets.to(device)\n",
        "\n",
        "            # Test set forward pass\n",
        "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
        "\n",
        "            # Test set loss\n",
        "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
        "            for step in range(num_steps):\n",
        "                test_loss += loss(test_mem[step], test_targets)\n",
        "            test_loss_hist.append(test_loss.item())\n",
        "\n",
        "            # Print train/test loss/accuracy\n",
        "            if counter % 50 == 0:\n",
        "                train_printer(\n",
        "                    data, targets, epoch,\n",
        "                    counter, iter_counter,\n",
        "                    loss_hist, test_loss_hist,\n",
        "                    test_data, test_targets)\n",
        "            counter += 1\n",
        "            iter_counter +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0SQQUzSV0fo",
        "outputId": "056d6627-36b2-4519-f4e8-b6c7516a4cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Iteration 0\n",
            "Train Set Loss: 52.26\n",
            "Test Set Loss: 48.39\n",
            "Train set accuracy for a single minibatch: 68.75%\n",
            "Test set accuracy for a single minibatch: 61.72%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 50\n",
            "Train Set Loss: 10.15\n",
            "Test Set Loss: 12.51\n",
            "Train set accuracy for a single minibatch: 89.06%\n",
            "Test set accuracy for a single minibatch: 85.94%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 100\n",
            "Train Set Loss: 9.79\n",
            "Test Set Loss: 10.19\n",
            "Train set accuracy for a single minibatch: 87.50%\n",
            "Test set accuracy for a single minibatch: 90.62%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 150\n",
            "Train Set Loss: 9.08\n",
            "Test Set Loss: 7.42\n",
            "Train set accuracy for a single minibatch: 92.19%\n",
            "Test set accuracy for a single minibatch: 90.62%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 200\n",
            "Train Set Loss: 9.30\n",
            "Test Set Loss: 7.93\n",
            "Train set accuracy for a single minibatch: 90.62%\n",
            "Test set accuracy for a single minibatch: 85.16%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 250\n",
            "Train Set Loss: 7.48\n",
            "Test Set Loss: 8.13\n",
            "Train set accuracy for a single minibatch: 92.19%\n",
            "Test set accuracy for a single minibatch: 88.28%\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "plt.plot(loss_hist)\n",
        "plt.plot(test_loss_hist)\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZje0XjhV3dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "# drop_last switched to False to keep all samples\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  for data, targets in test_loader:\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    test_spk, _ = net(data.view(data.size(0), -1))\n",
        "\n",
        "    # calculate total accuracy\n",
        "    _, predicted = test_spk.sum(dim=0).max(1)\n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "wrE6GtMOV6e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = []\n",
        "for layer in net.children():\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        layers.append(layer.state_dict()['weight'])\n",
        "\n",
        "print(layers[0])\n",
        "print(layers[1])"
      ],
      "metadata": {
        "id": "bv4gyVf9cKB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensions of the first layer:\")\n",
        "print(f\"  Number of rows: {layers[0].shape[0]}\")\n",
        "print(f\"  Number of columns: {layers[0].shape[1]}\")\n",
        "\n",
        "# Print the dimensions of the second layer\n",
        "print(\"\\nDimensions of the second layer:\")\n",
        "print(f\"  Number of rows: {layers[1].shape[0]}\")\n",
        "print(f\"  Number of columns: {layers[1].shape[1]}\")"
      ],
      "metadata": {
        "id": "WTXw2bClsrV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is provided in SNN Tutorial 3, but we know that here columns is the source, and rows are the target."
      ],
      "metadata": {
        "id": "sPZJ2hxiUcFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1=layers[0]\n",
        "layer2=layers[1]"
      ],
      "metadata": {
        "id": "32RAwckqDSxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# Create separate lists for source and target nodes\n",
        "source_node_labels = [f\"{0}:{j}\" for j in range(layer1.shape[1])]\n",
        "middle_node_labels = [f\"{1}:{j}\" for j in range(layer1.shape[0])]\n",
        "target_node_labels = [f\"{2}:{j}\" for j in range(layer2.shape[0])]\n",
        "\n",
        "#print(source_node_labels)\n",
        "#print(middle_node_labels)\n",
        "#print(target_node_labels)\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "G.add_nodes_from(source_node_labels, bipartite=0)\n",
        "G.add_nodes_from(middle_node_labels, bipartite=1)\n",
        "G.add_nodes_from(target_node_labels, bipartite=2)\n",
        "\n",
        "#print(G)"
      ],
      "metadata": {
        "id": "qiI2No6ip7bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add weighted edges\n",
        "for i in range(layer1.shape[0]):\n",
        "    # Loop through the columns of the random_array\n",
        "    for j in range(layer1.shape[1]):\n",
        "        # Get the corresponding node labels\n",
        "        source_node = source_node_labels[j]\n",
        "        middle_node = middle_node_labels[i]\n",
        "\n",
        "        # Add an edge between the nodes with the weight from the random_array\n",
        "        G.add_edge(source_node, middle_node, weight=layer1[i][j])\n",
        "\n",
        "for i in range(layer2.shape[0]):\n",
        "    # Loop through the columns of the random_array\n",
        "    for j in range(layer2.shape[1]):\n",
        "        # Get the corresponding node labels\n",
        "        middle_node = middle_node_labels[j]\n",
        "        target_node = target_node_labels[i]\n",
        "\n",
        "        # Add an edge between the nodes with the weight from the random_array\n",
        "        G.add_edge(middle_node, target_node, weight=layer2[i][j])"
      ],
      "metadata": {
        "id": "mQgcMIWWqX9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.algorithms import bipartite\n",
        "\n",
        "pos = dict()\n",
        "pos.update( (n, (0, i)) for i, n in enumerate(source_node_labels) ) # put nodes from X at x=1\n",
        "pos.update( (n, (1, i)) for i, n in enumerate(middle_node_labels) ) # put nodes from Y at x=2\n",
        "pos.update( (n, (2, i)) for i, n in enumerate(target_node_labels) ) # put nodes from Y at x=3\n",
        "nx.draw(G, pos=pos)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "wi673vNdqkC6",
        "outputId": "462df0fa-e2c5-4d8c-aa1a-3254fb7592df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtgElEQVR4nO3de7RdZX0u/u/c2QmEkHu4BYIGQW4KiFZFbBGQYgWh/gqBFjhqQYrQUYpAKTDKOR2gUIqijFOEITLEA4xy0woFKz9ucgQiFLlEIQJCgEC4hFzJJsm+rPOHhgLNDNl7rTXfNd/1+fxThwPW+1Bc7372s7LnLhqNRiMAAGCEelIHAACg3hRKAACaolACANAUhRIAgKYolAAANEWhBACgKQolAABNUSgBAGiKQgkAQFMUSgAAmqJQAgDQFIUSAICmKJQAADRFoQQAoCkKJQAATVEoAQBoikIJAEBTFEoAAJqiUAIA0BSFEgCApiiUAAA0RaEEAKApCiUAAE1RKAEAaIpCCQBAUxRKAACaolACANAUhRIAgKYolAAANEWhBACgKQolAABNUSgBAGiKQgkAQFMUSgAAmqJQAgDQFIUSAICmKJQAADSlN3UAgE41b+HrccuvFsSKVYMxboNR8dkPbBHvnbZx6lgAHadoNBqN1CEAOsUP7n0mLrz9yVjc11/610zeaHSctO928T8+MbPCZACdS6EEiIibHn4hTrrukRgYWv8rsbeniAsP3TU+t9uWbUwG0PkUSqDrff7ie+Kh55eM+O//0IxJ8aPj92xdIICaUSiBrrbXP98Rzy56o+nXec+UsfGzU/dpQSKA+vFT3kDX+vzF97SkTEZEPLvojfj/vnNPS14LoG4USqAr3fTwC019zL02v3xuSdz08AstfU2AOvCRN9CV3nfGzTHYhttvVBHx268f0PoXBuhgFkqg6/zg3mfaUiYjIgYbEf/nvnnteXGADqVQAl3n/J/+pq2v/08/ndvW1wfoNAol0HVeXz3Y3tdf1d7XB+g0CiXQVZ5+9fVKzpm3sJpzADqBQgl0lRt++Xwl51z3YDXnAHQChRLoKg8/vzSrcwA6gUIJdJUFS/uyOgegEyiUQFdZvqI1vxnn3QwNVXIMQEdQKIHs3XbbbVEURRRFEfOfq+bPNg6FRgl0D4USyNKNN94YPT09URRF7Lfffm/+942o5pE+Pa5XoIu48YBsXHPNNW+WyIMPPjjW9ptlixhVSRYLJdBNFEqg1r73ve/FqFGjoiiKOPzww9daIt/KQgnQem48oHYuuuiiN5fIY445JoaG8RMwFkqA1lMogY7XaDTinHPOebNEnnjiie+6RJa+loUSoOV6UwcAWJuhoaE488wz47zzzmvp61ooAVpPoQQ6xsDAQJx44olx8cUXt+0MCyVA6ymUQFKrV6+OY489Nq644opKzrNQArSeQglUrq+vL77whS/E9ddfX/nZFkqA1lMogUosWbIk/uIv/iJ+8pOfJM1hoQRoPYUSaJtXX301Zs2aFXfddVfqKG+yUAK0nkIJtNTzzz8fhxxySNx///2po6yVhRKg9RRKoGm//e1v4/Of/3zMmTMndZR3ZaEEaD03HjAijz76aGy//fZRFEVsu+22tSiTEdUtlG+sWlXJOQCdwEIJrLdf/OIXMWvWrHjuuedSRxmxqhbKZ+c9Xck5AJ3AQgms02233RZbbLFFFEURH//4x2tdJiMiihhd0Tm9seWWW1ZyFkBqCiXwNo1GI3784x/HtGnToiiK2G+//eKll15KHauGinjxxRdj7ty5qYMAtJ1CCcTQ0FBcddVVMWnSpOjp6Yk//dM/jddeey11rPYoqj1nxx13rOhAgHQUSuhSg4OD8Z3vfCc23njjGDVqVBx55JGxdOnS1LHar9Go/JwtttiimjMBElEooYv09/fH+eefH2PHjo3e3t44/vjjY8WKFaljVaoRA5Wf89JLL8Wjjz5aybkAKfgpb8jcypUr45xzzonzzz8/+vv7U8dJrqrHBr3znF133TUaVa2jABWzUEKGXn/99TjxxBOjt7c3xo4dG1/72teUyd+r6rFBaztnk002qeRsgKoplJCJJUuWxF/+5V/GqFGjYvz48XHRRRfF4GA15alOUi2UERELFy6Mhx56qJLzAarkI2+osVdeeSVOOOGEuOGGG3ycup5SLpQREbvvvrt/V0B2LJRQM/Pnz48/+ZM/iaIoYrPNNovrr79eQRmGlAvlGlOmTKkkA0BVFEqogSeffDL+6I/+KIqiiBkzZsR//Md/pI5UW6kXyoiIxYsXx3333VdJDoAq+MgbOtScOXPiS1/6Ujz44IOpo2SlExbKiIhPfOITlmUgGxZK6CCzZ8+OnXbaKYqiiF122UWZbINOWCjXmDRpUvuDAFRAoYSEGo1G3HHHHbHNNttEURSxxx57xOOPP546VtY6ZaGMiFi6dGncdddd7Q8D0GYKJVRsaGgobrzxxpg+fXr09PTEvvvuG88880zqWF2jkxbKiIi99967zUkA2k+hhAoMDg7GVVddFdOmTYtRo0bFwQcfHAsWLEgdqyt10kK5xvjx49uYBKD9FEpok/7+/rjkkkti4sSJ0dvbG0ceeWS89tprqWN1vU5bKCN+95uNbr311jamAWgvP+UNLbRq1ar49re/Hf/4j/8YfX19qeOwFp24UEZE7L///n7qG6gthRKatGLFijj33HPjggsuiFWrVqWOw7voxIVyjXHjxsWKFSvakAagvXzkDSOwdOnS+Ju/+ZsYPXp0bLzxxvG1r31NmayJTl0oIyL6+vri3//939uQBqC9LJSwnhYuXBgnn3xyXHXVVTE4WM3KRet18kIZEfG5z33OR99A7SiUsA4LFiyI448/Pn784x/7Ip+JTl4o1xg7dmy88cYbLUwD0F4+8oZ3eOaZZ+KP//iPoyiKmD59evzbv/2bMpmRTl8oIyJWrlwZN9xwQwvTALSXhRIi4vHHH4+jjz467rvvvtRRaLM6LJQREYcccohvZIDasFDStf7zP/8zdt111yiKInbaaSdlskvUYaFcY8MNN2xBEoD2UyjpGo1GI+66667YbrvtoiiK+IM/+IN49NFHU8eiYnVZKCN+91zTK6+8sgVpANpLoSRrjUYjbrrpppgxY0b09PTE3nvvHU899VTqWCRUp4UyIuKoo47y0TfQ8RRKsjM4OBhXX311bLLJJtHT0xMHHXRQzJ8/P3UsOkQRoys6p3V/RH2DDTZo2WsBtINCSRb6+/vj0ksvffP3Zh9xxBGxcOHC1LHoakXLXqm/vz8uv/zylr0eQKsplNTWqlWr4p/+6Z9i3LhxMWbMmDjuuONi2bJlqWPR6VrX8yo95+ijj/bRN9CxPDaIWlmxYkWcc845ceGFF/pVh4xMVaWsDeeMGTMm+vv7W/66AM2yUNLxli5dGieccMKbvzf7vPPOUyYZsUYM1PacgYGB+Jd/+ZeWvy5AsxRKOtLChQvjyCOPjFGjRsWkSZPi4osvjoGBaooAeavTY4PW5q//+q9jaGioLa8NMFI+8qZjvPDCC/FXf/VXccstt/izYrRN3R4btDZjxozxDRbQUSyUJPXUU0/FXnvtFUVRxFZbbRU333yzMklb1X2hjPjdo7G+8Y1vtO31AYZLoaRyc+bMid133z2Koojtttsu7r777tSR6CI5LJQREaeccoqPvoGOoVBSifvuuy+23377KIoidtlll3jooYdSR6JL5bBQrjF6dDUPaQd4NwolbdFoNOLWW2+NGTNmRFEU8YlPfCKeeOKJ1LEgm4UyImJoaCi+/vWvt/0cgHejUNIyjUYjrr/++jd/5eH+++/vVx7ScXJaKCMizjzzTD+gAySnUNKUwcHBuOyyy2LixInR09MThx56qF95SEfLaaFcw+/6BlJTKBm2/v7+uOCCC2Ls2LHR29sbX/7yl/3KQ2ojt4Uy4ncffZ955pmVnQfwTgol62XlypVx+umnx5gxY2LMmDFx6qmnxsqVK1PHgmHLcaGMiPj617/u1zICyXiwOaVef/31OOWUU+Kyyy6LwcFqvzhCu+S4UK6xwQYbeJQQkISFkrdZvHhxHHbYYdHT0xPjx4+PSy+9VJkkK7kulBG/+8G4U089tfJzARRKYsGCBbH//vtHURQxZcqUuPbaa/22GrKV80IZEXHBBRfE6tWrk5wNdC8feXepp59+Ov78z/887r///tRRoFI5L5RrbLDBBr4pBCploewic+bMiR133DGKooj3ve99yiRdKfeFco0TTjgh6flAd1EoM3ffffe9+dtqdtlll5g7d27qSJBUNyyUEREXX3yxJzEAlVEoM3TzzTfH1KlT3/yVh35bDfyXblkoIyLGjh2bOgLQJRTKDDQajbjyyitj4403jqIo4sADD4xFixaljgUdqVsWyjWOPvro1BGALqBQ1lSj0YhvfetbMWbMmOjp6YmjjjoqVqxYkToWdLxuWigjIi6//PLo6+tLHQPInEJZIwMDA3HGGWdEb29v9PT0xEknneQ3Y8AwddtCGRExbty41BGAzCmUHW716tVx9NFHR09PT4wePTrOPfdcDxqHJnTbQrnGEUcckToCkLGuL5QrVg3Er19cGg89tzh+/eLSWLFqIHWkWLFiRRx44IFRFEVssMEGcfnll3umHLRINy6UERFXX311LFu2LHUMIFNd+WDzJ19eHlf94rm48zevxHOL+uKtVa2IiK2nbBR7b79pHPGxrWO7zcZXkmnRokVxwAEHxOzZsys5D7pVEaMrOqfzrteJEyf65hRoi8678dro+UV9ccaP5sT/fWph6V/TiIhnF/XF9++bF9+/b1784bbT4uuf/2DMmLJRy/PMnz8/9t5773jqqada/tpAakXqAGv1Z3/2Z3HDDTekjgFkpms+8v7XB56Lfb551zrL5Nr836cWxj7fvCv+9YHnWpLjsccei0033TSKoogZM2Yok1C1qnpeZ/bJ+OEPfxhLlixJHQPITFcUyv9955Px9z+cE/2DI/uop3+wEX//wznxv+98ckR//9133x3jxo2Loihi5513jldffXVErwO0QFUf+XbwR8uTJ09OHQHITPaF8l8feC4uuPWJlrzWBbc+Edes51J53XXXRW9vbxRFEXvttZfnwEGHaEQ1P3hX1Tkj9dnPfjZ1BCAjWRfKNX9mspVO/9GceH7R2svh+eefH0VRRFEUMWvWLI/3gQ7UrY8Neqef/OQnfqMW0DJZF8oTrv5lDLX4U6ehxu9ed41jjjnmzRJ52mmntfYwoOW69bFBazN16tTUEYBMZPtT3k++vDwefWFpW1770ReWxuhpM2LgtflteX2gfSyUb7fvvvvG7bffnjoGUHPZLpTn/uTxtr7+5E99qa2vD7SHhfLt7rjjjnj55ZdTxwBqLttC+bMn2vuT1GO3+XBbXx9oDwvlf7f55punjgDUXJaF8vVVAzHCJwStv55RUYzesM2HAK1moVy7T37yk6kjADWWZaF86LnFbT+jKIoYs8X7234O0FoWyrW75557Yv58fy4cGJksC+Wdc1+p5Jyx7/tIJecArWOhLDdjxozUEYCayrJQPvrCkkrOGbP5dpWcA7SOhXLdPvIR3ygDw5dloVyyor+Sc4oNx1VyDtA6Fsp1e/DBB2PevHmpYwA1k2WhXD1Uza88K3pGV3IO0DoWync3c+bM1BGAmsmyUPZU9I9V1wUCupmFcv3ssssuqSMANZJloRyKoUrOqfMCAd3KQrl+5syZE08++WTqGEBNZFkoLZRAGQvl+nv/+z0aDVg/WRZKCyVQxkI5PDvssEPqCEANZFkoLZRAGQvl8PzmN7+Jxx57LHUMoMNlWSgtlEAZC+Xw7bzzzqkjAB0uy0JpoQTKWChHZptttkkdAehgWRZKCyVQxkI5Ms8880w88sgjqWMAHSrLQmmhBMpYKEdut912Sx0B6FBZFkoLJVDGQtmcGTNmpI4AdKAsC6WFEihjoWzO/PnzY/bs2aljAB0my0LZP1TVQtlbyTlA6xQxuqJz8r0f9thjj2g0GqljAB0ky0LZiKouuqKic4D6yft+2GKLLVJHADpIloUyGhVd5Hl/vYA8VfW+zfx+ePnll+NnP/tZ6hhAh8iyUPb0VLRQ+sgH6qeq920X3A+f+tSnfPQNRESmhbK3qOanKxsxUMk5QOtU9b7tlvth0003TR0B6ABZFkqPDQLKeGxQay1cuDBuvfXW1DGAxLIslB4bBJTx2KDW23///X30DV0uy0JpoQTKWCjbY8qUKakjAAllWSgtlEAZC2V7LFmyJG688cbUMYBEsiyUFkqgjIWyfQ4++GAffUOXyrJQWiiBMhbK9po4cWLqCEACWRZKCyVQxkLZXsuXL49rrrkmdQygYlkWSgslUMZC2X6HH354DA527z8/dKMsC6WFEihjoazGhAkTUkcAKpRlobRQAmUslNXo6+uLK664InUMoCJZFkoLJVDGQlmdL37xizEw0B2/ghK6XZaF0kIJlLFQVmv8+PGpIwAVyLJQWiiBMhbKaq1cuTIuueSS1DGANsuyUFoogTIWyup95Stf8dE3ZC7LQmmhBMpYKNPYaKONUkcA2ijLQmmhBMpYKNPo7++Pb33rW6ljAG2SZaG0UAJlLJTpnHTSSdHf3586BtAGWRZKCyVQxkKZlo++IU9ZFkoLJVDGQpnWwMBAnHvuualjAC2WZaG0UAJlLJTpnXHGGbFq1arUMYAWyrJQWiiBMhbKzjBu3LjUEYAWyrJQWiiBMhbKzjA4OBhnnXVW6hhAi2RZKC2UQBkLZec4++yzo6+vL3UMoAWyLJQWSqCMhbKz+F3fkIcsC2X/UFULZW8l5wCtU8Tois5xP6yPoaGhOPnkk1PHAJqUZaFsRKOik4qKzgHqx/2wvr75zW/G8uXLU8cAmpBloYxGRRe5rxdQP1W9b90PwzJx4sTUEYAmZFkoe3oqWigbVS2hQMtU9b51PwxLo9GIr3zlK6ljACOUZaHsLar56cpGDFRyDtA6Vb1v3Q/Dd8kll8SyZctSxwBGIMtC6bFBQBmPDepsPvqGesqyUHpsEFDGY4M63xe/+MXUEYBhyrJQWiiBMhbKznfFFVfE4sWLU8cAhiHLQmmhBMpYKOthypQpqSMAw5BlobRQAmUslPVx2GGHpY4ArKcsC6WFEihjoayPa6+9NhYuXJg6BrAesiyUFkqgjIWyXjbZZJPUEYD1kGWhtFACZSyU9XPQQQeljgC8iywLpYUSKGOhrJ+bbropFixYkDoGsA5ZFkoLJVDGQllP06dPTx0BWIcsC6WFEihjoayv/fbbL3UEoESWhdJCCZSxUNbXbbfdFs8//3zqGMBaZFkoLZRAGQtlvW299dapIwBrkWWhtFACZSyU9feHf/iHqSMA75BlobRQAmUslPX385//PObNm5c6BvAWWRZKCyVQxkKZh5kzZ6aOALxFloXSQgmUsVDm46Mf/WjqCMDvZVkoLZRAGQtlPh544IGYO3du6hhAZFooLZRAGQtlXnbcccfUEYDItFBaKIEyFsr87LLLLqkjQNfLslBaKIEyFsr8zJkzJx555JHUMaCrZVkoLZRAGQtlnnbbbbdoNBqpY0DXyrJQ9g9VtVD2VnIO0DpFjK7oHPdD1XbYYYfUEaBrZVkoG1HVd6lFRecA9eN+qNoTTzwRDzzwQOoY0JWyLJTRqOgi9/UC6qeq9637IYmPfvSjPvqGBLIslD09FV0mLi2on6ret+6HZLbZZpvUEaDrZFkoe4tqfrqyEQOVnAO0TlXvW/dDOvPmzYt77703dQzoKlkWSo8NAsp4bFB32HPPPX30DRXKslB6bBBQxmODusdWW22VOgJ0jSwLpYUSKGOh7B4vvvhi3H777aljQFfIslBaKIEyFsru8ulPf9pH31CBLAulhRIoY6HsPptttlnqCJC9LAulhRIoY6HsPq+++mrcfPPNqWNA1rIslBZKoIyFsjsdeOCBMVTRr+WFbpRlobRQAmUslN1r2rRpqSNAtrIslBZKoIyFsnstXrw4rrvuutQxIEtZFkoLJVDGQtndZs2aFYOD/t1Aq2VZKC2UQBkLJZMnT04dAbKTZaG0UAJlLJQsX748rrrqqtQxICtZFkoLJVDGQklExJFHHhkDAwOpY0A2siyUFkqgjIWSNSZOnJg6AmQjy0JpoQTKWChZo6+vL7773e+mjgFZyLJQWiiBMhZK3urYY4+N/v7+1DGg9rIslBZKoIyFkncaP3586ghQe1kWSgslUMZCyTutWrUqLrrootQxoNayLJQWSqCMhZK1OfHEE2PVqlWpY0BtZVkoLZRAGQslZSZMmJA6AtRWloXSQgmUsVBSZvXq1XHuueemjgG1lGWhtFACZSyUrMsZZ5wRb7zxRuoYUDtZFsr+oaoWyt5KzgFap4jRFZ3jfqgrH33D8GVZKBvRqOikoqJzgPpxP9TVwMBAnHXWWaljQK1kWSijUdFF7usF1E9V71v3Q62dffbZ0dfXlzoG1EaWhbKnp6KFslHVEgq0TFXvW/dD7XngOay/LAtlb1HNT1c2YqCSc4DWqep9636ov6GhoTjllFNSx4BayLJQemwQUMZjgxiOb3zjG7F8+fLUMaDjZVkoPTYIKOOxQQzXxIkTU0eAjpdlobRQAmUslAxXo9GI4447LnUM6GhZFkoLJVDGQslIXHrppbF06dLUMaBjZVkoLZRAGQslIzV58uTUEaBjZVkoLZRAGQslI9VoNOILX/hC6hjQkbIslBZKoIyFkmb84Ac/iEWLFqWOAR0ny0JpoQTKWChp1tSpU1NHgI6TZaG0UAJlLJS0wqxZs1JHgI6SZaG0UAJlLJS0wnXXXRcvvfRS6hjQMbIslBZKoIyFklbZYostUkeAjpFlobRQAmUslLTSAQcckDoCdIQsC6WFEihjoaSVbrnllnj++edTx4DksiyUFkqgjIWSVtt6661TR4DksiyUFkqgjIWSdthnn31SR4CksiyUFkqgjIWSdrjzzjtj3rx5qWNAMlkWSgslUMZCSbvMnDkzdQRIJstCaaEEylgoaac999wzdQRIIstCaaEEylgoaad77703nnjiidQxoHJZFkoLJVDGQkm7bb/99qkjQOWyLJQWSqCMhZIqfOhDH0odASqVZaG0UAJlLJRU4eGHH45f/epXqWNAZbIslP1DVS2UvZWcA7ROEaMrOsf90O0++MEPRqPRSB0DKpFloWxEVW/goqJzgPpxPxCx0047pY4AlciyUEajoovc1wuon6ret+4HImLu3Lnx0EMPpY4BbZdloezpqWih9FEG1E9V71v3A7+3++67++ib7GVZKHuLan66shEDlZwDtE5V71v3A2+17bbbpo4AbZVlofTYIKCMxwaRwtNPPx333HNP6hjQNlkWSo8NAsp4bBCpfPKTn/TRN9nKslBaKIEyFkpS2nrrrVNHgLbIslBaKIEyFkpSmj9/ftx5552pY0DLZVkoLZRAGQslqe2zzz4++iY7WRZKCyVQxkJJJ9hss81SR4CWyrJQWiiBMhZKOsGrr74at9xyS+oY0DJZFkoLJVDGQkmnOOCAA2JoqJoBBNoty0JpoQTKWCjpJNOmTUsdAVoiy0JpoQTKWCjpJIsXL44bbrghdQxoWpaF0kIJlLFQ0mkOOeSQGBz0DQj1lmWhtFACZSyUdKLJkyenjgBNybJQWiiBMhZKOtHy5cvjyiuvTB0DRizLQmmhBMpYKOlURx11VAwMDKSOASOSZaG0UAJlLJR0sgkTJqSOACOSZaG0UAJlLJR0sjfeeCO++93vpo4Bw5ZlobRQAmUslHS6Y489Nvr7+1PHgGHJslBaKIEyFkrqYPz48akjwLBkWSgtlEAZCyV1sGrVqvjmN7+ZOgastywLpYUSKGOhpC5OPvnkWL16deoYsF6yLJQWSqCMhZI6GTduXOoIsF6yLJQWSqCMhZI6GRgYiLPPPjt1DHhXWRbK/qGqFsreSs4BWqeI0RWd436gNc4666x44403UseAdcqyUDaiUdFJRUXnAPXjfqB1/NQ3nS7LQhmNii5yXy+gfqp637ofaKHBwcE4/fTTU8eAUlkWyp6eihbKRlVLKNAyVb1v3Q+02HnnnRcrVqxIHQPWKstC2VtU89OVjRio5Bygdap637ofaAcffdOpsiyUHhsElPHYIOqs0WjEiSeemDoG/DdZFkqPDQLKeGwQdXfRRRfFsmXLUseAt8myUFoogTIWSnIwadKk1BHgbbIslBZKoIyFkhw0Go045phjUseAN2VZKC2UQBkLJbn43ve+F4sXL04dAyIi00JpoQTKWCjJyZQpU1JHgIjItFBaKIEyFkpyc/jhh6eOAHkWSgslUMZCSW6uueaaWLhwYeoYdLksC6WFEihjoSRHm2yySeoIdLksC6WFEihjoSRXBx10UOoIdLEsC6WFEihjoSRXN910UyxYsCB1DLpUloXSQgmUsVCSs+nTp6eOQJfKslBaKIEyFkpyt99++6WOQBfKslBaKIEyFkpyd9ttt8Vzzz2XOgZdJstCaaEEylgo6Qbvec97Ukegy2RZKC2UQBkLJd1ijz32SB2BLpJlobRQAmUslHSL2bNnx29/+9vUMegSWRZKCyVQxkJJN9l2221TR6BLZFkoLZRAGQsl3Wa33XZLHYEukGWhtFACZSyUdJtHHnkkHnvssdQxyFyWhdJCCZSxUNKNdt5559QRyFyWhdJCCZSxUNKtdthhh9QRyFiWhbJ/qKqFsreSc4DWKWJ0Ree4H+gsv/nNb+KXv/xl6hhkKstC2YhGRScVFZ0D1I/7gc7z4Q9/OBqNqr5G0k2yLJTRqOgi9/UC6qeq9637gQ41c+bM1BHIUJaFsqenou++fJcH9VPV+9b9QId69tln4957700dg8xkWSh7i2p+urIRA5WcA7ROVe9b9wOdbM899/TRNy2VZaH02CCgjMcGwe9Mnz49dQQykmWh9NggoIzHBsHvvPTSS3HHHXekjkEmsiyUFkqgjIUS/su+++7ro29aIstCaaEEylgo4e2mTZuWOgIZyLJQWiiBMhZKeLtFixbFzTffnDoGNZdlobRQAmUslPDfHXjggT76pilZFkoLJVDGQglrN2nSpNQRqLEsC6WFEihjoYS1W7ZsWVx//fWpY1BTWRZKCyVQxkIJ5Q499NAYHPTNEMOXZaG0UAJlLJSwbhMmTEgdgRrKslBaKIEyFkpYt76+vvj+97+fOgY1k2WhtFACZSyU8O6+9KUvxcCA30fP+suyUFoogTIWSlg/48aNSx2BGsmyUFoogTIWSlg/q1evjosvvjh1DGoiy0JpoQTKWChh/Z1wwgk++ma9ZFkoLZRAGQslDM+GG26YOgI1kGWhtFACZSyUMDyDg4Nx/vnnp45Bh8uyUFoogTIWShi+0047Lfr7+1PHoINlWSgtlEAZCyWMjI++WZcsC6WFEihjoYSRGRoain/4h39IHYMOlWWhtFACZSyUMHLnnHNOrFy5MnUMOlCWhdJCCZSxUEJzNtpoo9QR6EBZFkoLJVDGQgnNaTQa8bd/+7epY9BhsiyUFkqgjIUSmvftb387+vr6Usegg2RZKPuHqlooeys5B2idIkZXdI77gbz5Xd+8VZaFshGNik4qKjoHqB/3A/n78pe/nDoCHSLLQhmNii5yXy+gfqp637of6AKXXXZZLF++PHUMOkCWhbKnp6KFslHVEgq0TFXvW/cDXWLChAmpI9ABsiyUvUU1P13ZiIFKzgFap6r3rfuBbjJr1qzUEUgsy0LpsUFAGY8Ngta77rrrYtGiRaljkFCWhdJjg4AyHhsE7TF16tTUEUgoy0JpoQTKWCihfQ444IDUEUgky0JpoQTKWCihfW655ZZ45ZVXUscggSwLpYUSKGOhhPbabLPNUkcggSwLpYUSKGOhhPbba6+9UkegYlkWSgslUMZCCe139913x4svvpg6BhXKslBaKIEyFkqoxpZbbpk6AhXKslBaKIEyFkqozkc+8pHUEahIloXSQgmUsVBCdR588MGYN29e6hhUIMtCaaEEylgooVozZ85MHYEKZFkoLZRAGQslVG/HHXdMHYE2y7JQWiiBMhZKqN7cuXNj7ty5qWPQRlkWSgslUMZCCWlYKfOWZaG0UAJlLJSQznvf+97UEWiTLAulhRIoY6GEdJ599tl49NFHU8egDbIslBZKoIyFEtLaddddU0egDbIslBZKoIyFEtLbfPPNU0egxbIslBZKoIyFEtJ7+eWXY/bs2alj0EJZFkoLJVDGQgmdYY899kgdgRbKslBaKIEyFkroHJMnT04dgRbJslBaKIEyFkroHEuWLInbb789dQxaIMtC2T9U1ULZW8k5QOsUMbqic9wPsD4+/elPR6PRSB2DJmVZKBtR1f8wi4rOAerH/QDra+ONN04dgSZlWSijUdFF7usF1E9V71v3A6y3vr6+uPHGG1PHoAlZFsqenooWShM91E9V71v3AwzLwQcf7KPvGsuyUPYW1fx0ZSMGKjkHaJ2q3rfuBxi+DTfcMHUERijLQumxQUAZjw2CzrV69eq48sorU8dgBLIslB4bBJTx2CDobEcddVQMVfS0Flony0JpoQTKWCih840ZMyZ1BIYpy0JpoQTKWCih8w0ODsZ3vvOd1DEYhiwLpYUSKGOhhHo4/vjjffRdI1kWSgslUMZCCfXR2+s3TtVFloXSQgmUsVBCfTQajTj//PNTx2A9ZFkoLZRAGQsl1Mtpp50WAwOe69rpsiyUFkqgjIUS6mf06NGpI/AusiyUFkqgjIUS6un0009PHYF1yLJQWiiBMhZKqKfzzjsv+vv7U8egRJaF0kIJlLFQQn154HnnyrJQWiiBMhZKqLfjjjsudQTWIstCaaEEylgood4uvfTSWLVqVeoYvEOWhdJCCZSxUEL9bbjhhqkj8A5ZFkoLJVDGQgl5OOyww1JH4C2yLJQWSqCMhRLycO2110ZfX1/qGPxeloXSQgmUsVBCPsaNG5c6Ar+XZaG0UAJlLJSQl8985jOpIxCZFkoLJVDGQgl5+elPfxqvv/566hhdL8tCaaEEylgoIT/jx49PHaHrZVkoLZRAGQsl5OljH/tY6ghdLctC2T9U1ULZW8k5QOsUMbqic9wPUKX7778/Fi1alDpG18qyUDaiUdFJRUXnAPXjfoCqTZ06NXWErpVloYxGRRe5rxdQP1W9b90PkMSOO+6YOkJXyrJQ9vRUtFA2qlpCgZap6n3rfoAk5s6dGwsWLEgdo+tkWSh7i2p+urIRA5WcA7ROVe9b9wOkM3369NQRuk6WhdJjg4AyHhsE3WGrrbZKHaGrZFkoPTYIKOOxQdAdXnjhhXjmmWdSx+gaWRZKCyVQxkIJ3WObbbZJHaFrZFkoLZRAGQsldJfJkyenjtAVsiyUFkqgjIUSusuSJUvi17/+deoY2cuyUFoogTIWSug+H/jAB1JHyF6WhdJCCZSxUEJ3Gjt2bOoIWcuyUFoogTIWSuhOK1eujNmzZ6eOka0sC6WFEihjoYTutccee6SOkK0sC6WFEihjoYTuNmqUb/baIctCaaEEylgoobsNDQ3FT3/609QxspNlobRQAmUslMBnPvOZ1BGyk2WhtFACZSyUQEREURSpI2Qly0JpoQTKWCiBNa6++urUEbKRZaG0UAJlLJTAGkcccUTqCNnIslBaKIEyFkrgrXz03RpZFkoLJVDGQgm804UXXpg6Qu1lWSgtlEAZCyXwTl/96ldTR6i9LAulhRIoY6EE1sZH383JslBaKIEyFkqgzN/93d+ljlBbWRZKCyVQxkIJlPnnf/7n1BFqK8tCaaEEylgogXXx0ffIZFko+4eqWih7KzkHaJ0iRld0jvsB6urwww9PHaF2siyUjWhUdJLvYoAy7geoq2uuuSaGKhqncpFloYxGRRe5rxdQP1W9b90PUGujRvlz0MORZaHs6alooWxUtYQCLVPV+9b9ALX38Y9/PHWE2siyUPYW1XxX0YiBSs4BWqeq9637AervF7/4RQwMeC+vjywLpccGAWU8NggYjtGjq/lBvrrL8scQPTYIKOOxQcBwTZ8+PV588cW3/XevLFsZs595Ld5YPRhjx4yKj8+cGptO2DBRwvSyLJQWSqCMhRIYrgULFsTKlSvj508viW/8/0/Ek6+8HgND//3PSff2FLHdphvHyfu9Pz690+YJkqaTZaG0UAJlLJTAcG2w1c6x3Wk/ilEbTVjnXzcw1IjHX1oex/yfB2PS2NFx6ZEfjo9tM7WilGn5M5RNsEBA/VgogeGY+tmTYrMjzoueseOH9fcteaM/Dvvu7PjqtQ+3J1iHybJQWiiBMhZKYH1tetjZsfEu+0bEyH8l4w8feiGO/N7sVsbqSFkWSgslUMZCCayPqZ89KcbO/FBENP/7vX/+1Gtx8nUPtyBV58qyUFoogTIWSuDdbLDVzjHug/u09DVv+OUL8YunX2vpa3aSLAulhRIoY6EE3s2mh/7Ptrzul654oC2v2wmyLJQWSqCMhRJYl7Hv+4Po2WCjpj/mXpu+1YNx++Mvt/x1O0GWhdJCCZSxUALrMmX/E9r6+mf+25y2vn4qWRZKCyVQxkIJrMuo8e19buRLy1a19fVTybJQWiiBMhZKoEzPuMmVnPPKspWVnFOlLAulhRIoY6EEymy0/Sfb8mcn3+mmR19897+oZrIslBZKoIyFEiiz4Xt3q+Scnz/1aiXnVCnLQmmhBMpYKIEyoyZMq+ScFxb7yLsWeopG6ggAQN2MquaThYHBgUrOqVKWhXLzSRtVcs7g0vwma8hdVe9b9wPUT1Xv26p6SpV6Uwdoh922mhT3/nZR28/5+HbT4yP/639FxH/9ns+3/mHeKv5gL/B2jUbjbf/3nf/5gVWbx68q+BBjbffDW/+z+wGqt7Z7IcX9sNtWk9p/SMWKxlv/P5mJeQtfj09942dtP+euk/eK907buO3nAK3jfgDKuB9GLsuPvKv6l5Tb/xigG7gfgDLuh5HLslBGRIwb094/WNvu1wfax/0AlHE/jEy2hfK0/bdv6+v//Wd2aOvrA+3jfgDKuB9GJttC+T8+MbNt/3A9EXHUHu9t06sD7eZ+AMq4H0Ym20IZEfHtw3ar1esC1XE/AGXcD8OXdaH83G5bxodmTGrpa+6+9aT43G5btvQ1geq5H4Ay7ofhy7pQRkT86Pg94z1Txrbktd4zZaP44Vf2bMlrAem5H4Ay7ofhyb5QRkT87NR9mv5OY/etJ8XPTt27NYGAjuF+AMq4H9Zflg82L3PTwy/ESdc9EgND6/+P3NtTxIWH7pr1TA24H4By7od311WFco0f3PtMXHj7k7G4r7/0r5m80ej46qffn+1PYwFr534AyrgfynVloXyreQtfj1t+tSBWrBqMcRuMis9+YIssn2APDJ/7ASjjfni7ri+UAAA0pyt+KAcAgPZRKAEAaIpCCQBAUxRKAACaolACANAUhRIAgKYolAAANEWhBACgKQolAABNUSgBAGiKQgkAQFMUSgAAmqJQAgDQFIUSAICmKJQAADRFoQQAoCkKJQAATVEoAQBoikIJAEBTFEoAAJqiUAIA0BSFEgCApiiUAAA0RaEEAKApCiUAAE1RKAEAaIpCCQBAUxRKAACaolACANAUhRIAgKYolAAANEWhBACgKQolAABNUSgBAGiKQgkAQFMUSgAAmqJQAgDQlP8HDK1/cHIvCOEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all edge attributes\n",
        "edge_attributes = nx.get_edge_attributes(G, 'weight')\n",
        "\n",
        "# Print the edge attributes\n",
        "print(edge_attributes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POQ-G9XF0Our",
        "outputId": "f38f7106-6b27-43cf-932d-35b3917e738e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}